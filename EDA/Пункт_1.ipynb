{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98bcc7a1-5b0e-4a2f-ba6d-d195517ba2ae",
   "metadata": {},
   "source": "# Характеристика логов: количество записей, структура, поля"
  },
  {
   "cell_type": "code",
   "id": "194ff693-ff07-41d4-81f9-4b11beb30cb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-08T22:25:02.055045Z",
     "start_time": "2026-01-08T22:24:58.299058Z"
    }
   },
   "source": [
    "import os, glob\n",
    "import pandas as pd\n",
    "\n",
    "root = \"/Users/slvic/Downloads/HDFS_v1\"\n",
    "\n",
    "def find_one(root: str, name: str):\n",
    "    hits = glob.glob(os.path.join(root, \"**\", name), recursive=True)\n",
    "    return hits[0] if hits else None\n",
    "\n",
    "# --- 0) Что вообще есть в папке ---\n",
    "p_raw   = find_one(root, \"HDFS.log\")\n",
    "p_feat  = find_one(root, \"Event_occurrence_matrix.csv\")\n",
    "p_lab   = find_one(root, \"anomaly_label.csv\")\n",
    "p_trace = find_one(root, \"Event_traces.csv\")\n",
    "p_tmpl  = find_one(root, \"HDFS.log_templates.csv\")\n",
    "\n",
    "print(\"Найденные файлы:\")\n",
    "print(\"RAW HDFS.log:\", p_raw or \"-\")\n",
    "print(\"Event_occurrence_matrix.csv:\", p_feat or \"-\")\n",
    "print(\"anomaly_label.csv:\", p_lab or \"-\")\n",
    "print(\"Event_traces.csv:\", p_trace or \"-\")\n",
    "print(\"HDFS.log_templates.csv:\", p_tmpl or \"-\")\n",
    "\n",
    "# --- 1) Характеристика RAW-лога ---\n",
    "if p_raw:\n",
    "    # считаем строки без загрузки в память\n",
    "    n_lines = 0\n",
    "    with open(p_raw, \"r\", errors=\"ignore\") as f:\n",
    "        for _ in f:\n",
    "            n_lines += 1\n",
    "    print(f\"\\nRAW лог (HDFS.log): количество записей (строк): {n_lines:,}\")\n",
    "else:\n",
    "    print(\"\\nRAW лог (HDFS.log) не найден или не используется.\")\n",
    "\n",
    "# --- 2) Характеристика preprocessed (структура/поля) ---\n",
    "assert p_feat and p_lab, \"Не найдены Event_occurrence_matrix.csv и/или anomaly_label.csv\"\n",
    "\n",
    "df_feat_head = pd.read_csv(p_feat, nrows=5)\n",
    "df_lab_head  = pd.read_csv(p_lab, nrows=5)\n",
    "\n",
    "print(\"\\nPREPROCESSED: структуры файлов (поля/колонки)\")\n",
    "print(\"Event_occurrence_matrix.csv колонки:\", df_feat_head.columns.tolist()[:20], \"...\")\n",
    "print(\"anomaly_label.csv колонки:\", df_lab_head.columns.tolist())\n",
    "\n",
    "# число записей (строк) в CSV (быстро, без полной загрузки)\n",
    "n_feat = sum(1 for _ in open(p_feat, \"r\", errors=\"ignore\")) - 1\n",
    "n_lab  = sum(1 for _ in open(p_lab, \"r\", errors=\"ignore\")) - 1\n",
    "print(f\"\\nEvent_occurrence_matrix.csv: количество записей: {n_feat:,}\")\n",
    "print(f\"anomaly_label.csv: количество записей: {n_lab:,}\")\n",
    "\n",
    "# --- 3) (Опционально) собрать единый DF и показать типы/пропуски ---\n",
    "df_feat = pd.read_csv(p_feat)\n",
    "df_lab  = pd.read_csv(p_lab)\n",
    "\n",
    "# нормализуем имя ключа\n",
    "df_feat.rename(columns={\"block_id\":\"BlockId\",\"blockid\":\"BlockId\"}, inplace=True)\n",
    "df_lab.rename(columns={\"block_id\":\"BlockId\",\"blockid\":\"BlockId\"}, inplace=True)\n",
    "\n",
    "df = df_feat.merge(df_lab[[\"BlockId\",\"Label\"]], on=\"BlockId\", how=\"left\")\n",
    "\n",
    "print(\"\\nИтоговый DataFrame (features + label):\")\n",
    "print(\"Количество записей:\", f\"{len(df):,}\")\n",
    "print(\"Количество полей:\", df.shape[1])\n",
    "print(\"Первые 25 полей:\", df.columns.tolist()[:25], \"...\")\n",
    "print(\"\\nТипы первых 25 полей:\")\n",
    "print(df.dtypes.head(25))\n",
    "print(\"\\nПропуски (топ-10):\")\n",
    "print(df.isna().sum().sort_values(ascending=False).head(10))\n",
    "print(\"\\nПример строк:\")\n",
    "display(df.head(5))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найденные файлы:\n",
      "RAW HDFS.log: /Users/slvic/Downloads/HDFS_v1/HDFS.log\n",
      "Event_occurrence_matrix.csv: /Users/slvic/Downloads/HDFS_v1/preprocessed/Event_occurrence_matrix.csv\n",
      "anomaly_label.csv: /Users/slvic/Downloads/HDFS_v1/preprocessed/anomaly_label.csv\n",
      "Event_traces.csv: /Users/slvic/Downloads/HDFS_v1/preprocessed/Event_traces.csv\n",
      "HDFS.log_templates.csv: /Users/slvic/Downloads/HDFS_v1/preprocessed/HDFS.log_templates.csv\n",
      "\n",
      "RAW лог (HDFS.log): количество записей (строк): 11,175,629\n",
      "\n",
      "PREPROCESSED: структуры файлов (поля/колонки)\n",
      "Event_occurrence_matrix.csv колонки: ['BlockId', 'Label', 'Type', 'E1', 'E2', 'E3', 'E4', 'E5', 'E6', 'E7', 'E8', 'E9', 'E10', 'E11', 'E12', 'E13', 'E14', 'E15', 'E16', 'E17'] ...\n",
      "anomaly_label.csv колонки: ['BlockId', 'Label']\n",
      "\n",
      "Event_occurrence_matrix.csv: количество записей: 575,061\n",
      "anomaly_label.csv: количество записей: 575,061\n",
      "\n",
      "Итоговый DataFrame (features + label):\n",
      "Количество записей: 575,061\n",
      "Количество полей: 33\n",
      "Первые 25 полей: ['BlockId', 'Label_x', 'Type', 'E1', 'E2', 'E3', 'E4', 'E5', 'E6', 'E7', 'E8', 'E9', 'E10', 'E11', 'E12', 'E13', 'E14', 'E15', 'E16', 'E17', 'E18', 'E19', 'E20', 'E21', 'E22'] ...\n",
      "\n",
      "Типы первых 25 полей:\n",
      "BlockId     object\n",
      "Label_x     object\n",
      "Type       float64\n",
      "E1           int64\n",
      "E2           int64\n",
      "E3           int64\n",
      "E4           int64\n",
      "E5           int64\n",
      "E6           int64\n",
      "E7           int64\n",
      "E8           int64\n",
      "E9           int64\n",
      "E10          int64\n",
      "E11          int64\n",
      "E12          int64\n",
      "E13          int64\n",
      "E14          int64\n",
      "E15          int64\n",
      "E16          int64\n",
      "E17          int64\n",
      "E18          int64\n",
      "E19          int64\n",
      "E20          int64\n",
      "E21          int64\n",
      "E22          int64\n",
      "dtype: object\n",
      "\n",
      "Пропуски (топ-10):\n",
      "Type       558223\n",
      "BlockId         0\n",
      "E23             0\n",
      "E17             0\n",
      "E18             0\n",
      "E19             0\n",
      "E20             0\n",
      "E21             0\n",
      "E22             0\n",
      "E24             0\n",
      "dtype: int64\n",
      "\n",
      "Пример строк:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                    BlockId  Label_x  Type  E1  E2   E3  E4  E5  E6  E7  ...  \\\n",
       "0  blk_-1608999687919862906  Success   NaN   0   0  203   0  10   7   0  ...   \n",
       "1   blk_7503483334202473044  Success   NaN   0   2    1   0   3   0   0  ...   \n",
       "2  blk_-3544583377289625738     Fail  21.0   0   0  203   0   3   0   0  ...   \n",
       "3  blk_-9073992586687739851  Success   NaN   0   3    0   0   3   0   0  ...   \n",
       "4   blk_7854771516489510256  Success   NaN   0   3    1  15   3   0   0  ...   \n",
       "\n",
       "   E21  E22  E23  E24  E25  E26  E27  E28  E29  Label_y  \n",
       "0   10    1   10    0    4   10    0    0    0   Normal  \n",
       "1    3    1    3    0    0    3    0    0    0   Normal  \n",
       "2    3    1    3    0    0    3    0    0    0  Anomaly  \n",
       "3    3    1    3    0    0    3    0    0    0   Normal  \n",
       "4    3    1    3    0    0    3    0    0    0   Normal  \n",
       "\n",
       "[5 rows x 33 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BlockId</th>\n",
       "      <th>Label_x</th>\n",
       "      <th>Type</th>\n",
       "      <th>E1</th>\n",
       "      <th>E2</th>\n",
       "      <th>E3</th>\n",
       "      <th>E4</th>\n",
       "      <th>E5</th>\n",
       "      <th>E6</th>\n",
       "      <th>E7</th>\n",
       "      <th>...</th>\n",
       "      <th>E21</th>\n",
       "      <th>E22</th>\n",
       "      <th>E23</th>\n",
       "      <th>E24</th>\n",
       "      <th>E25</th>\n",
       "      <th>E26</th>\n",
       "      <th>E27</th>\n",
       "      <th>E28</th>\n",
       "      <th>E29</th>\n",
       "      <th>Label_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blk_-1608999687919862906</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blk_7503483334202473044</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blk_-3544583377289625738</td>\n",
       "      <td>Fail</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blk_-9073992586687739851</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blk_7854771516489510256</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T11:05:32.863313Z",
     "start_time": "2026-01-09T10:52:27.020945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- проверка входа ---\n",
    "assert p_raw and os.path.exists(p_raw), \"HDFS.log не найден (p_raw пустой или файл не существует).\"\n",
    "\n",
    "# --- regex под HDFS.log (LogHub/HDFS) ---\n",
    "# Пример строки (типично):\n",
    "# 081109 203615 148 INFO dfs.DataNode$DataXceiver: Receiving block blk_-1608999687919862906 src: /10.250.19.102:54106 dest: /10.250.19.102:50010\n",
    "#\n",
    "# Группы:\n",
    "# date: 081109\n",
    "# time: 203615\n",
    "# pid: 148\n",
    "# level: INFO\n",
    "# component: dfs.DataNode$DataXceiver\n",
    "# message: Receiving block ...\n",
    "LOG_RE = re.compile(\n",
    "    r\"^(?P<date>\\d{6})\\s+\"\n",
    "    r\"(?P<time>\\d{6})\\s+\"\n",
    "    r\"(?P<pid>\\d+)\\s+\"\n",
    "    r\"(?P<level>[A-Z]+)\\s+\"\n",
    "    r\"(?P<component>[^:]+):\\s*\"\n",
    "    r\"(?P<message>.*)$\"\n",
    ")\n",
    "\n",
    "# BlockId ищем внутри message\n",
    "BLK_RE = re.compile(r\"\\bblk_[-\\d]+\\b\")\n",
    "\n",
    "def parse_line(line: str):\n",
    "    m = LOG_RE.match(line)\n",
    "    if not m:\n",
    "        return None\n",
    "\n",
    "    gd = m.groupdict()\n",
    "\n",
    "    # timestamp: yyMMdd HHMMSS -> pandas datetime\n",
    "    # В HDFS датасете год обычно 2008/2009 (yy из date)\n",
    "    # pandas сам подставит 20yy.\n",
    "    ts = pd.to_datetime(gd[\"date\"] + \" \" + gd[\"time\"], format=\"%y%m%d %H%M%S\", errors=\"coerce\")\n",
    "\n",
    "    msg = gd[\"message\"]\n",
    "    blk = None\n",
    "    mblk = BLK_RE.search(msg)\n",
    "    if mblk:\n",
    "        blk = mblk.group(0)\n",
    "\n",
    "    return {\n",
    "        \"timestamp\": ts,\n",
    "        \"level\": gd[\"level\"],\n",
    "        \"component\": gd[\"component\"],\n",
    "        \"message\": msg,\n",
    "        \"BlockId\": blk,\n",
    "        \"pid\": gd[\"pid\"],\n",
    "    }\n",
    "\n",
    "# --- потоковый парсинг (без загрузки всего файла в память одной строкой) ---\n",
    "rows = []\n",
    "bad = 0\n",
    "\n",
    "with open(p_raw, \"r\", errors=\"ignore\") as f:\n",
    "    for line in f:\n",
    "        line = line.rstrip(\"\\n\")\n",
    "        rec = parse_line(line)\n",
    "        if rec is None:\n",
    "            bad += 1\n",
    "            continue\n",
    "        rows.append(rec)\n",
    "\n",
    "df_logs = pd.DataFrame(rows)\n",
    "\n",
    "print(\"Parsed rows:\", len(df_logs))\n",
    "print(\"Unparsed rows:\", bad, f\"({bad/(bad+len(df_logs)+1e-9):.2%})\")\n",
    "display(df_logs.head(5))\n",
    "\n",
    "# --- приведение типов ---\n",
    "df_logs[\"level\"] = df_logs[\"level\"].astype(\"string\")\n",
    "df_logs[\"component\"] = df_logs[\"component\"].astype(\"string\")\n",
    "df_logs[\"message\"] = df_logs[\"message\"].astype(\"string\")\n",
    "df_logs[\"BlockId\"] = df_logs[\"BlockId\"].astype(\"string\")\n",
    "df_logs[\"pid\"] = pd.to_numeric(df_logs[\"pid\"], errors=\"coerce\").astype(\"Int32\")\n",
    "\n",
    "# --- базовая характеристика ---\n",
    "print(\"\\nХарактеристика распарсенного HDFS.log:\")\n",
    "print(\"Строк:\", f\"{len(df_logs):,}\")\n",
    "print(\"Колонки:\", list(df_logs.columns))\n",
    "print(\"Диапазон дат:\", df_logs[\"timestamp\"].min(), \"->\", df_logs[\"timestamp\"].max())\n",
    "print(\"Уровни:\", df_logs[\"level\"].value_counts().head(10).to_dict())\n",
    "print(\"Компоненты (топ-10):\")\n",
    "display(df_logs[\"component\"].value_counts().head(10).to_frame(\"count\"))\n",
    "print(\"Уникальных BlockId:\", int(df_logs[\"BlockId\"].nunique(dropna=True)))\n",
    "\n",
    "# --- сохранить parquet для пункта 6 ---\n",
    "out_path = \"hdfs_logs.parquet\"\n",
    "df_logs.to_parquet(out_path, index=False)\n",
    "print(f\"\\nSaved parquet: {out_path}\")"
   ],
   "id": "78e78135263d7156",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed rows: 11175629\n",
      "Unparsed rows: 0 (0.00%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "            timestamp level                     component  \\\n",
       "0 2008-11-09 20:35:18  INFO      dfs.DataNode$DataXceiver   \n",
       "1 2008-11-09 20:35:18  INFO              dfs.FSNamesystem   \n",
       "2 2008-11-09 20:35:19  INFO      dfs.DataNode$DataXceiver   \n",
       "3 2008-11-09 20:35:19  INFO      dfs.DataNode$DataXceiver   \n",
       "4 2008-11-09 20:35:19  INFO  dfs.DataNode$PacketResponder   \n",
       "\n",
       "                                             message  \\\n",
       "0  Receiving block blk_-1608999687919862906 src: ...   \n",
       "1  BLOCK* NameSystem.allocateBlock: /mnt/hadoop/m...   \n",
       "2  Receiving block blk_-1608999687919862906 src: ...   \n",
       "3  Receiving block blk_-1608999687919862906 src: ...   \n",
       "4  PacketResponder 1 for block blk_-1608999687919...   \n",
       "\n",
       "                    BlockId  pid  \n",
       "0  blk_-1608999687919862906  143  \n",
       "1  blk_-1608999687919862906   35  \n",
       "2  blk_-1608999687919862906  143  \n",
       "3  blk_-1608999687919862906  145  \n",
       "4  blk_-1608999687919862906  145  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>level</th>\n",
       "      <th>component</th>\n",
       "      <th>message</th>\n",
       "      <th>BlockId</th>\n",
       "      <th>pid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-11-09 20:35:18</td>\n",
       "      <td>INFO</td>\n",
       "      <td>dfs.DataNode$DataXceiver</td>\n",
       "      <td>Receiving block blk_-1608999687919862906 src: ...</td>\n",
       "      <td>blk_-1608999687919862906</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-11-09 20:35:18</td>\n",
       "      <td>INFO</td>\n",
       "      <td>dfs.FSNamesystem</td>\n",
       "      <td>BLOCK* NameSystem.allocateBlock: /mnt/hadoop/m...</td>\n",
       "      <td>blk_-1608999687919862906</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-11-09 20:35:19</td>\n",
       "      <td>INFO</td>\n",
       "      <td>dfs.DataNode$DataXceiver</td>\n",
       "      <td>Receiving block blk_-1608999687919862906 src: ...</td>\n",
       "      <td>blk_-1608999687919862906</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-11-09 20:35:19</td>\n",
       "      <td>INFO</td>\n",
       "      <td>dfs.DataNode$DataXceiver</td>\n",
       "      <td>Receiving block blk_-1608999687919862906 src: ...</td>\n",
       "      <td>blk_-1608999687919862906</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-11-09 20:35:19</td>\n",
       "      <td>INFO</td>\n",
       "      <td>dfs.DataNode$PacketResponder</td>\n",
       "      <td>PacketResponder 1 for block blk_-1608999687919...</td>\n",
       "      <td>blk_-1608999687919862906</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Характеристика распарсенного HDFS.log:\n",
      "Строк: 11,175,629\n",
      "Колонки: ['timestamp', 'level', 'component', 'message', 'BlockId', 'pid']\n",
      "Диапазон дат: 2008-11-09 20:35:18 -> 2008-11-11 11:16:28\n",
      "Уровни: {'INFO': 10812836, 'WARN': 362793}\n",
      "Компоненты (топ-10):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                      count\n",
       "component                                                  \n",
       "dfs.FSNamesystem                                    3700245\n",
       "dfs.DataNode$PacketResponder                        3413350\n",
       "dfs.DataNode$DataXceiver                            2518678\n",
       "dfs.FSDataset                                       1407597\n",
       "dfs.DataBlockScanner                                 120046\n",
       "dfs.DataNode                                           7002\n",
       "dfs.DataNode$DataTransfer                              6946\n",
       "dfs.DataNode$BlockReceiver                             1718\n",
       "dfs.PendingReplicationBlocks$PendingReplication...       47"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>component</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dfs.FSNamesystem</th>\n",
       "      <td>3700245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dfs.DataNode$PacketResponder</th>\n",
       "      <td>3413350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dfs.DataNode$DataXceiver</th>\n",
       "      <td>2518678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dfs.FSDataset</th>\n",
       "      <td>1407597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dfs.DataBlockScanner</th>\n",
       "      <td>120046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dfs.DataNode</th>\n",
       "      <td>7002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dfs.DataNode$DataTransfer</th>\n",
       "      <td>6946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dfs.DataNode$BlockReceiver</th>\n",
       "      <td>1718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dfs.PendingReplicationBlocks$PendingReplicationMonitor</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уникальных BlockId: 575061\n",
      "\n",
      "Saved parquet: hdfs_logs.parquet\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-09T11:36:35.988003Z",
     "start_time": "2026-01-09T11:36:35.976710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\n",
    "'''\n",
    "Timestamp - дата и время события;\n",
    "Level - уровень логирования (INFO и WARN);\n",
    "Component - программный компонент HDFS (Java-класс или вложенный класс), из которого было сгенерировано лог-сообщение;\n",
    "Message - текст лог-сообщения, в котором описано конкретное действие или событие, выполненное компонентом;\n",
    "BlockId - идентификатор блока данных (trace-id);\n",
    "Pid - идентификатор процесса-истоничка.\n",
    "''')"
   ],
   "id": "a40d481b538a822",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Timestamp - дата и время события;\n",
      "Level - уровень логирования (INFO и WARN);\n",
      "Component - программный компонент HDFS (Java-класс или вложенный класс), из которого было сгенерировано лог-сообщение;\n",
      "Message - текст лог-сообщения, в котором описано конкретное действие или событие, выполненное компонентом;\n",
      "BlockId - идентификатор блока данных (trace-id);\n",
      "Pid - идентификатор процесса-истоничка.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
